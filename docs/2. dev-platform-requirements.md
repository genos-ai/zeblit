# Internal AI Development Platform - Requirements Document

## Executive Summary
A browser-based, AI-powered collaborative development platform similar to Replit, designed for internal enterprise use. The platform features a team of AI agents that work together to help developers build, test, and deploy applications through natural language interactions.

## Core Platform Requirements

### 1. Platform Architecture

#### 1.1 Deployment & Infrastructure
- **Browser-based**: Fully accessible through modern web browsers
- **Cross-platform**: Must run on Apple Mac and Ubuntu servers
- **Hardware**: Currently targeting Apple M4 MAX (utilizing GPU when beneficial)
- **Container runtime**: 
  - OrbStack for macOS (Apple Silicon optimized)
  - Docker/containerd for Ubuntu servers
- **Local hosting**: Primary deployment on-premise
- **Cloud deployment**: Support for Azure, Kubernetes, and AKS deployment
- **Backend language**: Python-based backend (FastAPI preferred)

#### 1.2 User Management
- **Multi-tenancy**: Support for multiple concurrent users
- **Role-based access**:
  - Regular users: Create and manage own projects
  - Admins: Manage users and platform configuration
  - Superusers: Full platform visibility and control
- **Authentication**: SSO integration with corporate identity providers

### 2. Development Environment

#### 2.1 IDE Features
- **Code editor**: Monaco-based editor (VS Code engine)
- **File management**: Browse and edit files/folders
- **Preview mode**: In-platform web application preview
- **Terminal access**: Integrated terminal for command execution
- **Git integration**: Full source code management capabilities

#### 2.2 Container Environment
- **Isolated environments**: Kubernetes-managed containers per project
- **Pre-installed tools**: Python, Node.js, common frameworks
- **Persistent storage**: Code persists across container restarts
- **Resource management**: Auto-scaling and idle shutdown

### 3. AI Agent Team

#### 3.1 Agent Roster
1. **Development Manager**
   - Coordinates team activities
   - Parses requirements
   - Assigns tasks to agents
   - Monitors progress
   - Resolves conflicts

2. **Product Manager**
   - Translates business requirements
   - Creates user stories
   - Validates implementations
   - UI/UX recommendations

3. **Data Analyst/Scientist**
   - Data model design
   - Query optimization
   - Analytics implementation
   - Visualization creation

4. **Senior Software Engineer**
   - Core application development
   - Business logic implementation
   - Code quality assurance
   - Complex algorithm development

5. **Architect**
   - System design
   - Technology selection
   - Scalability planning
   - Design pattern implementation

6. **Platform Engineer**
   - Deployment configuration
   - Container setup
   - Infrastructure as code
   - Performance monitoring

#### 3.2 Agent Capabilities
- **Inter-agent communication**: Agents collaborate on tasks
- **Manager coordination**: Development Manager orchestrates all activities
- **Real-time visibility**: Each agent has a dedicated UI tab
- **Status tracking**: Live updates on agent activities
- **Git integration**: Each agent can work on separate branches

### 4. LLM Integration

#### 4.1 Multi-Provider Support
- **Primary (Default)**: Anthropic Claude models
  - Claude 3 Opus: Complex tasks, architecture, comprehensive features
  - Claude 3.5 Sonnet: Routine coding, quick fixes, cost-effective tasks
- **Secondary Options**:
  - OpenAI: GPT-4, GPT-3.5-turbo models
  - Google: Gemini Pro models
- **Model selection**: Automatic based on task complexity, user override available

#### 4.2 External Services
- **Email**: Resend for notifications and alerts
- **No offline mode**: Internet connection required for all features

#### 4.3 AI Features
- **Code generation**: Direct Claude API integration with role-specific prompts
- **Intelligent routing**: Opus for complex tasks, Sonnet for routine work
- **Debugging assistance**: Analyze console logs and JavaScript errors
- **Documentation**: Inline help and API documentation
- **Code review**: Automated security and quality checks

### 5. Application Development

#### 5.1 Project Creation
- **Wizard-based**: LLM-guided project setup
- **Single app focus**: One active app per user at a time
- **Project archiving**: Save and switch between projects
- **Templates**: Pre-built project templates (React, Next.js, Python API, Full-stack)
- **Technology stacks**: Support for Python, React, Next.js, etc.

#### 5.2 Development Workflow
- **Requirements gathering**: Natural language to technical specs
- **Automatic scaffolding**: Generate project structure
- **Live preview**: Real-time application preview
- **Hot reload**: Instant updates during development
- **User-initiated deployment**: One-click deploy with user control

### 6. Debugging & Monitoring

#### 6.1 Console & Error Capture (CRITICAL FEATURE)
- **Real-time Console Interception**: 
  - Capture ALL console methods (log, error, warn, info, debug, trace)
  - Intercept unhandled errors and promise rejections
  - Capture network request failures
  - Maintain stack traces and source locations
- **WebSocket Streaming**: 
  - Instant transmission of console data to backend
  - Bidirectional communication for debugging commands
  - Automatic reconnection with message queuing
- **AI Agent Visibility**:
  - AI agents have FULL access to console logs and errors
  - Contextual analysis with logs before/after errors
  - Pattern recognition for common error types
  - Automatic error classification (null reference, syntax, network, etc.)

#### 6.2 Debug Capabilities
- **Error Navigation**: Click on errors to jump to source code
- **Console Filtering**: Filter by log level, search, and time
- **Export Functionality**: Download console logs for analysis
- **Performance Monitoring**: Real-time metrics and profiling
- **Network Analysis**: API call inspection with request/response details

#### 6.3 AI-Powered Debugging
- **Automatic Error Analysis**: 
  - AI analyzes errors immediately upon detection
  - Provides root cause analysis
  - Suggests specific code fixes
  - Explains why the error occurred
- **Contextual Debugging**:
  - AI sees console logs around errors (5 seconds before/after)
  - Understands application state from log messages
  - Correlates multiple errors to find patterns
- **Proactive Fixes**:
  - AI suggests fixes in agent chat with full context
  - Can apply fixes automatically with user approval
  - Learns from previous debugging sessions
- **Error Prevention**:
  - AI suggests preventive measures
  - Identifies potential issues before they cause errors
  - Recommends best practices based on error patterns

#### 6.4 Console UI Features
- **Split View**: Console output alongside code editor
- **Real-time Updates**: Live streaming of console messages
- **Syntax Highlighting**: Color-coded log levels
- **Collapsible Stack Traces**: Expandable error details
- **Search & Filter**: Find specific messages quickly
- **Clear & Export**: Manage console output effectively

### 7. UI/UX Requirements

#### 7.1 Layout
```
┌────────────────────────────────────────────────────────┐
│ Header: Logo, User Info, Settings, Git Status          │
├────────────────────────────────────────────────────────┤
│ ┌──────────┬─────────────────────┬──────────────────┐ │
│ │ Agent    │   Code Editor       │   App Preview    │ │
│ │ Chat     │                     │                  │ │
│ │ (Left)   │   (Center)          │   (Right)        │ │
│ └──────────┴─────────────────────┴──────────────────┘ │
│ ┌────────────────────────────────────────────────────┐ │
│ │ Agent Tabs: [DevMgr][PM][Data][Eng][Arch][Plat]   │ │
│ │ Shows real-time agent activities and outputs       │ │
│ └────────────────────────────────────────────────────┘ │
└────────────────────────────────────────────────────────┘
```

#### 7.2 Agent Chat Interface
- **Position**: Left sidebar
- **Model selector**: Dropdown for LLM choice
- **Context awareness**: Access to current code/project
- **History**: Conversation persistence within current project session
- **Agent tabs**: Each shows full conversation with thinking process
- **Interactive**: Agents can ask clarifying questions to user
- **Real-time updates**: Live status of what each agent is working on

### 8. Git Integration

#### 8.1 Version Control
- **Built-in Git**: Full Git functionality
- **Branch management**: Visual branch overview
- **Agent branches**: Each agent works on separate branches
- **Merge coordination**: Dev Manager handles merges

#### 8.2 Collaboration
- **Code attribution**: Track which agent wrote what
- **Commit history**: Clear agent-attributed commits
- **Pull requests**: Internal PR workflow
- **Conflict resolution**: Agents attempt automatic resolution, escalate to user when needed
- **Merge strategies**: Smart merging with Dev Manager coordination

### 9. Security & Compliance

#### 9.1 Access Control
- **Network isolation**: Containers on isolated networks
- **Secret management**: Secure credential storage
- **Audit logging**: All actions tracked
- **Data protection**: Encryption at rest and in transit

#### 9.2 Code Security
- **Static analysis**: Automated security scanning
- **Dependency scanning**: Vulnerability detection
- **Compliance checks**: Internal policy enforcement
- **Access restrictions**: Role-based code access

### 10. Technical Stack

#### 10.1 Frontend
- **Framework**: React 18+ with TypeScript
- **UI Components**: Tailwind CSS, shadcn/ui
- **Editor**: Monaco Editor
- **State Management**: TanStack Query
- **WebSocket**: Real-time agent communication

#### 10.2 Backend
- **Framework**: FastAPI (Python)
- **Database**: PostgreSQL with SQLAlchemy
- **Task Queue**: Celery with Redis
- **WebSocket**: Python WebSocket server
- **Container Orchestration**: 
  - Phase 1: Docker Compose with OrbStack (macOS)
  - Phase 2: Docker + Kubernetes APIs (hybrid)
  - Phase 3: Full Kubernetes (local OrbStack K8s)
  - Production: Azure Kubernetes Service (AKS)

#### 10.3 AI/ML
- **Primary LLM**: Anthropic Claude (Direct API integration)
  - Claude 3 Opus for complex tasks
  - Claude 3.5 Sonnet for routine tasks
- **Fallback LLMs**: OpenAI GPT-4, Google Gemini Pro
- **Message Bus**: Redis Pub/Sub for agent coordination
- **Cost Tracking**: Custom usage tracking with model-based routing
- **Prompt Management**: Agent-specific prompt templates

## Implementation Priorities

### Phase 1: Core Platform with Docker Mode (Months 1-3)
1. Basic IDE with file management
2. Python backend setup (FastAPI)
3. Docker-based container orchestration via OrbStack
4. User authentication and role management
5. Single agent implementation (Engineer) for testing

### Phase 2: AI Integration with Hybrid Mode (Month 3-4)
1. **Claude integration** - Direct Anthropic API setup
2. Multi-LLM provider fallback system
3. Full agent team implementation
4. Inter-agent communication system
5. Git integration with agent branches
6. Kubernetes API introduction alongside Docker

### Claude Integration Implementation

```python
# Agent-specific Claude integration
class AgentClaudeIntegration:
    def __init__(self, agent_type):
        self.agent_type = agent_type
        self.client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        
    async def process_task(self, task, project_context):
        # Determine model based on task
        model = self._select_model(task)
        
        # Build conversation with project context
        messages = [
            {
                "role": "user",
                "content": f"""
                Project Context:
                - Language: {project_context['language']}
                - Framework: {project_context['framework']}
                - Current Files: {project_context['file_tree']}
                - Previous Code: {project_context['relevant_code']}
                
                Task: {task['description']}
                Requirements: {task['requirements']}
                """
            }
        ]
        
        response = await self.client.messages.create(
            model=model,
            max_tokens=4000,
            temperature=0.2,
            system=AGENT_PROMPTS[self.agent_type],
            messages=messages
        )
        
        return self._parse_code_response(response)
    
    def _select_model(self, task):
        # Smart model selection
        complexity_indicators = ['architecture', 'design', 'refactor', 'optimize', 'security']
        if any(indicator in task['description'].lower() for indicator in complexity_indicators):
            return 'claude-3-opus-20240229'
        return 'claude-3-5-sonnet-20241022'
```

### Phase 3: Multi-Agent System with Full K8s (Month 4-5)
1. Agent UI tabs with real-time updates
2. Collaborative workflows between agents
3. Advanced debugging capabilities
4. Full Kubernetes migration for production parity
5. Container resource optimization

### Phase 4: Advanced Features & Production (Month 5-6)
1. Multi-app support with project templates
2. Deployment pipelines to Azure/AKS
3. Advanced permissions and audit logging
4. Performance optimization and scaling
5. Production deployment preparation

## Platform Benefits with OrbStack

### Development Velocity
- **Instant container startup**: <1 second container launch
- **Native performance**: No virtualization overhead on Apple Silicon
- **Simplified networking**: Automatic `*.orb.local` domains
- **Direct debugging**: SSH into containers with `orb shell`

### Resource Efficiency
- **50% less memory**: Compared to Docker Desktop
- **Native ARM64**: No emulation for M-series Macs
- **Efficient file sync**: Fast volume mounting
- **GPU access**: Direct access to Apple Silicon GPU

### Migration Path Benefits
1. **Docker → Kubernetes**: Seamless transition when needed
2. **Local → Cloud**: Identical container behavior
3. **Development → Production**: Same orchestration patterns
4. **Single user → Multi-tenant**: Progressive scaling

## Development Environment Setup

### Local Development with OrbStack (Phased Approach)

#### Phase 1: Docker Mode (Months 1-3)
Start with Docker Compose for rapid development and simpler debugging:

```yaml
# docker-compose.yml for OrbStack
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://user:pass@postgres:5432/devplatform
      - CONTAINER_MODE=docker
      - ORBSTACK_DOMAIN=true
    volumes:
      - ./backend:/app
      - /var/run/docker.sock:/var/run/docker.sock
  
  postgres:
    image: postgres:16
    environment:
      - POSTGRES_PASSWORD=devpassword
    volumes:
      - postgres-data:/var/lib/postgresql/data
  
  redis:
    image: redis:7-alpine
  
  # Agent workers
  agent-engine:
    build: ./agents
    deploy:
      replicas: 6  # One per agent type
    environment:
      - AGENT_TYPES=dev_manager,product_manager,data_analyst,engineer,architect,platform_engineer
    
  # User containers created dynamically via Docker API

volumes:
  postgres-data:
  user-code:
```

**Benefits:**
- Faster iteration on agent logic
- Simple debugging with `docker logs` and `orb shell`
- Automatic preview URLs (e.g., `project-123.orb.local`)
- Direct container access for troubleshooting

#### Phase 2: Hybrid Mode (Month 3-4)
Introduce Kubernetes APIs while maintaining Docker simplicity:

```python
# backend/container_orchestrator.py
class ContainerOrchestrator:
    def __init__(self):
        self.mode = os.getenv('CONTAINER_MODE', 'docker')
        self.is_orbstack = self._detect_orbstack()
        
        if self.mode == 'hybrid':
            self.docker_client = docker.from_env()
            self.k8s_client = kubernetes.client.ApiClient()
    
    def _detect_orbstack(self):
        """Auto-detect if running on OrbStack"""
        return os.path.exists('/run/orbstack.sock')
    
    def create_user_environment(self, user_id, project_id):
        if self.mode in ['docker', 'hybrid']:
            return self._create_docker_container(user_id, project_id)
        else:
            return self._create_k8s_pod(user_id, project_id)
```

#### Phase 3: Full Kubernetes Mode (Month 4+)
Transition to Kubernetes for production parity:

```yaml
# kubernetes/local-dev.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: platform-backend
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: backend
        image: dev-platform/backend:latest
        env:
        - name: CONTAINER_MODE
          value: "kubernetes"
---
apiVersion: v1
kind: Service
metadata:
  name: platform-backend
spec:
  type: LoadBalancer
  ports:
  - port: 8000
  selector:
    app: platform-backend
```

### OrbStack-Specific Features

#### Auto-Detection and Configuration
```python
class OrbStackIntegration:
    def __init__(self):
        self.is_orbstack = os.path.exists('/run/orbstack.sock')
        self.features = {
            'instant_domains': self.is_orbstack,
            'gpu_passthrough': self.is_orbstack and self._has_gpu(),
            'native_arm64': platform.machine() == 'arm64'
        }
    
    def get_preview_url(self, project_id):
        if self.features['instant_domains']:
            return f"http://{project_id}.orb.local"
        return f"http://localhost:{self.get_mapped_port(project_id)}"
    
    def optimize_container_config(self, config):
        if self.features['native_arm64']:
            config['platform'] = 'linux/arm64'
        return config
```

#### Resource Optimization
```python
# Leverage OrbStack's efficient resource management
ORBSTACK_CONTAINER_DEFAULTS = {
    'memory_limit': '512m',  # OrbStack handles memory more efficiently
    'cpu_quota': 50000,      # 0.5 CPU
    'restart_policy': {'Name': 'unless-stopped'},
    'network_mode': 'orbstack' if is_orbstack else 'bridge'
}
```

### Migration Timeline

```
Phase 1: Docker Mode (Months 1-3)
├── Core platform development
├── Agent implementation
├── Basic container management
└── Local testing with docker-compose

Phase 2: Hybrid Mode (Month 3-4)
├── Add Kubernetes APIs
├── Test pod scheduling locally
├── Implement resource quotas
└── Network policy testing

Phase 3: Full K8s Mode (Month 4+)
├── Complete Kubernetes migration
├── Production-like environment
├── Horizontal pod autoscaling
└── Ready for cloud deployment
```

### Container Images
- **Base development image**: Python 3.12 + Node.js 20 + common tools
- **AI agent image**: Includes LangChain, model libraries
- **Lightweight user containers**: Minimal overhead per developer

### OrbStack Development Commands

```bash
# Start platform locally
orb start                          # Start OrbStack
docker-compose up -d               # Launch platform services

# Access services
open http://localhost:8000         # Platform UI
open http://redis.orb.local:6379   # Redis (if exposed)
open http://project-1.orb.local    # User's app preview

# Debug containers
orb shell backend                  # SSH into backend container
orb shell user-123-project-456    # Debug user's container
docker logs agent-engine -f        # Watch agent logs

# Monitor resources
orb status                         # Overall resource usage
docker stats                       # Per-container metrics

# Kubernetes transition (Phase 3)
orb kube start                     # Enable K8s cluster
kubectl apply -f k8s/              # Deploy to local K8s
kubectl port-forward svc/backend 8000:8000
```

## Clarified Requirements

### Agent Memory & Context
- **Current Session Only**: Agents remember conversations within current app development session
- **No Cross-Project Memory**: Each project starts fresh
- **Chat History**: Maintained for the duration of the active project

### Code Generation Strategy (Claude-First Approach)

**Default Models:**
- **Claude 3 Opus**: For complex code generation, architecture decisions, and comprehensive implementations
- **Claude 3.5 Sonnet**: For routine coding tasks, quick fixes, and cost-effective development

**Model Selection Logic:**
```python
class ClaudeCodeGenerator:
    def __init__(self):
        self.anthropic = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
        
    async def select_model(self, task_complexity):
        """Choose between Opus and Sonnet based on requirements"""
        if task_complexity in ['architecture', 'complex_algorithm', 'full_feature']:
            return 'claude-3-opus-20240229'
        else:
            return 'claude-3-5-sonnet-20241022'
    
    async def generate_code(self, agent_role, task, context):
        model = await self.select_model(task.complexity)
        
        system_prompt = self._get_agent_prompt(agent_role)
        
        response = await self.anthropic.messages.create(
            model=model,
            max_tokens=4000,
            temperature=0.2,  # Lower for more consistent code
            system=system_prompt,
            messages=[
                {"role": "user", "content": f"Context: {context}\n\nTask: {task.description}"}
            ]
        )
        
        return {
            'code': response.content[0].text,
            'model_used': model,
            'tokens_used': response.usage.total_tokens
        }
```

**Agent-Specific Prompts:**
```python
AGENT_PROMPTS = {
    'engineer': """You are a senior software engineer. Generate clean, efficient, 
                   well-documented code following best practices. Include error handling 
                   and consider edge cases.""",
    
    'architect': """You are a system architect. Focus on scalable design patterns, 
                    proper abstractions, and long-term maintainability.""",
    
    'data_analyst': """You are a data analyst. Write efficient data processing code 
                       with clear documentation of data transformations.""",
    
    'platform_engineer': """You are a platform engineer. Generate infrastructure code, 
                           deployment configs, and DevOps scripts."""
}
```

**Cost Optimization:**
- Use Sonnet for: Bug fixes, simple features, code formatting, documentation
- Use Opus for: New services, complex algorithms, system design, refactoring
- Automatic fallback from Opus to Sonnet if rate limited

### External Integrations
- **Email Service**: Resend for notifications
- **LLM Providers**: 
  - OpenAI (GPT-4, GPT-3.5)
  - Anthropic (Claude models)
  - Google (Gemini models)
- **No Offline Mode**: Internet connection required

### Container Resource Limits (Suggested)
**Per User Container:**
- CPU: 1-2 vCPU cores
- Memory: 2-4GB RAM
- Storage: 10GB persistent volume
- Network: Rate limited to prevent abuse

**Platform Limits:**
- Max concurrent users: 50 (adjustable)
- Total container pool: 100 containers
- Idle timeout: 30 minutes (container sleeps)
- Wake time: <2 seconds with OrbStack

### Agent Communication Architecture (Suggested)

#### Message Bus Design
```python
# Redis-based message bus for agent coordination
class AgentMessageBus:
    def __init__(self):
        self.redis_client = redis.Redis(host='redis', decode_responses=True)
        self.pubsub = self.redis_client.pubsub()
    
    def publish_task(self, task_type, project_id, payload):
        channel = f"project:{project_id}:tasks"
        message = {
            'id': str(uuid.uuid4()),
            'type': task_type,
            'project_id': project_id,
            'timestamp': datetime.now().isoformat(),
            'payload': payload,
            'status': 'pending'
        }
        self.redis_client.lpush(f"queue:{task_type}", json.dumps(message))
        self.redis_client.publish(channel, json.dumps(message))
        return message['id']
    
    def agent_subscribe(self, agent_type, project_id):
        # Agents subscribe to relevant channels
        channels = [
            f"project:{project_id}:tasks",
            f"agent:{agent_type}:direct",
            "broadcast:all_agents"
        ]
        self.pubsub.subscribe(channels)
        return self.pubsub
```

**Message Flow:**
1. User request → Development Manager
2. Dev Manager publishes tasks to message bus
3. Relevant agents pick up tasks from their queues
4. Agents publish results back to bus
5. Dev Manager coordinates and responds to user

### Code Generation Options (Easier than claude-code)

**Option 1: Direct LLM Integration (Recommended)**
```python
class CodeGenerationService:
    def __init__(self):
        self.providers = {
            'openai': OpenAI(),
            'anthropic': Anthropic(),
            'gemini': GoogleGenerativeAI()
        }
    
    async def generate_code(self, prompt, language, provider='openai'):
        # Use GPT-4 or Claude-3 directly with code-optimized prompts
        system_prompt = f"You are an expert {language} developer..."
        return await self.providers[provider].complete(prompt, system_prompt)
```

**Option 2: Open Source Models**
- CodeLlama 70B for on-premise deployment
- StarCoder for faster, smaller model
- Continue.dev integration for IDE features

### LLM Cost Tracking (Claude-Optimized)

```python
class LLMCostTracker:
    # Approximate costs per 1K tokens (as of 2025)
    PRICING = {
        # Claude models (primary)
        'claude-3-opus': {'input': 0.015, 'output': 0.075},
        'claude-3-5-sonnet': {'input': 0.003, 'output': 0.015},
        
        # Fallback models
        'gpt-4': {'input': 0.03, 'output': 0.06},
        'gpt-3.5-turbo': {'input': 0.001, 'output': 0.002},
        'gemini-pro': {'input': 0.00025, 'output': 0.0005}
    }
    
    async def track_usage(self, user_id, model, tokens_in, tokens_out):
        cost = (tokens_in * self.PRICING[model]['input'] + 
                tokens_out * self.PRICING[model]['output']) / 1000
        
        # Store in database
        await self.db.insert({
            'user_id': user_id,
            'timestamp': datetime.now(),
            'model': model,
            'tokens_in': tokens_in,
            'tokens_out': tokens_out,
            'cost_usd': cost
        })
        
        # Check limits
        monthly_total = await self.get_monthly_cost(user_id)
        if monthly_total > USER_MONTHLY_LIMIT:
            raise CostLimitExceeded(f"Monthly limit of ${USER_MONTHLY_LIMIT} exceeded")
```

**Cost Management Features:**
- Real-time usage dashboard per user
- Automatic model selection based on task complexity
- Claude Sonnet for 80% of tasks (5x cheaper than Opus)
- Claude Opus only for complex architectural decisions
- Monthly/daily limits with alerts

### Data Privacy Measures (Suggested)

**1. Project Isolation:**
```python
class ProjectIsolation:
    def create_agent_context(self, project_id, user_id):
        return {
            'project_id': project_id,
            'user_id': user_id,
            'allowed_paths': [f'/workspace/{user_id}/{project_id}'],
            'env_vars': self.get_project_env(project_id),
            'secrets': self.get_project_secrets(project_id)
        }
    
    def validate_agent_access(self, agent_request, context):
        # Ensure agent only accesses allowed resources
        if not any(agent_request.path.startswith(p) for p in context['allowed_paths']):
            raise SecurityException("Access denied to path")
```

**2. Data Sanitization:**
- Automatic PII detection in agent responses
- Secrets scanning before committing code
- Separate namespaces per project in message bus
- Agent contexts cleared between projects

**3. Audit Trail:**
```python
class PrivacyAudit:
    async def log_agent_action(self, agent, action, project_id):
        # Log all agent actions for security review
        await self.audit_db.insert({
            'timestamp': datetime.now(),
            'agent': agent,
            'action': action,
            'project_id': project_id,
            'data_accessed': self.classify_data_sensitivity(action)
        })
```

### Additional Clarifications

- **Git Conflicts**: Agents attempt automatic resolution, escalate to user when needed
- **Project Templates**: Include React, Next.js, Python API, Full-stack templates
- **Debugging**: Agents monitor all browser console errors, network failures, runtime exceptions
- **Multi-App**: One active app per user (can archive and create new)
- **Deployment**: User-initiated with one-click deploy to configured targets
- **Agent Conversations**: Each agent tab shows full conversation history with thinking process

## Open Questions

## Claude Integration Benefits

### Why Claude for Code Generation
1. **Superior code quality**: Claude excels at understanding context and generating well-structured code
2. **Longer context window**: 200K tokens allows entire codebases in context
3. **Better reasoning**: Explains architectural decisions and trade-offs
4. **Safety**: Less likely to generate harmful or insecure code
5. **Cost efficiency**: Sonnet provides excellent quality at 1/5 the cost of Opus

### Model Selection Strategy
- **Claude 3.5 Sonnet (Default - 80% of tasks)**:
  - Bug fixes and simple features
  - Code formatting and refactoring
  - Unit test generation
  - Documentation writing
  - Basic CRUD operations
  
- **Claude 3 Opus (Complex tasks - 20% of tasks)**:
  - System architecture design
  - Complex algorithm implementation
  - Security-critical code
  - Performance optimization
  - Large-scale refactoring

## Implementation Questions

1. **Message Bus Technology**: Use Redis Pub/Sub or Apache Kafka for agent communication?
2. **Agent Priority**: How to prioritize tasks when multiple agents need the same resource?
3. **Code Templates**: Which specific frameworks/versions for project templates?
4. **Error Recovery**: How should agents recover from LLM API failures?
5. **User Notifications**: When/how to notify users of agent progress?

### Example: Engineer Agent Using Claude

```python
class EngineerAgent:
    def __init__(self):
        self.name = "Senior Engineer"
        self.claude = ClaudeCodeGenerator()
        
    async def handle_user_request(self, request):
        # Example: User says "Create a login form with email and password"
        
        # Step 1: Analyze request complexity
        complexity = self.analyze_complexity(request)
        
        # Step 2: Generate code using appropriate Claude model
        if complexity == 'simple':
            # Use Sonnet for standard login form
            code = await self.claude.generate_with_sonnet(
                task="Create a React login form component",
                context={
                    'framework': 'React',
                    'styling': 'Tailwind CSS',
                    'validation': 'react-hook-form'
                }
            )
        else:
            # Use Opus for complex auth system
            code = await self.claude.generate_with_opus(
                task="Design secure authentication system",
                context={
                    'requirements': ['JWT', 'refresh tokens', 'MFA'],
                    'security': 'OWASP compliant'
                }
            )
        
        # Step 3: Test and validate generated code
        validation = await self.validate_code(code)
        
        # Step 4: Communicate with other agents if needed
        if validation.needs_review:
            await self.request_architect_review(code)
        
        return code
```

### Required API Configuration

```bash
# Environment variables needed
ANTHROPIC_API_KEY=sk-ant-...  # Primary - Claude API
OPENAI_API_KEY=sk-...          # Fallback - GPT models
GOOGLE_API_KEY=...             # Fallback - Gemini models
RESEND_API_KEY=re_...          # Email notifications

# Model defaults (configurable)
DEFAULT_COMPLEX_MODEL=claude-3-opus-20240229
DEFAULT_SIMPLE_MODEL=claude-3-5-sonnet-20241022
MODEL_SELECTION_THRESHOLD=0.7  # Complexity score for Opus vs Sonnet
```

## Success Metrics

- **Developer Productivity**: 50% reduction in project setup time
- **Code Quality**: 90% of code passes security/quality checks
- **Platform Adoption**: 80% of developers using within 6 months
- **User Satisfaction**: >4.5/5 satisfaction score

## Appendix

### A. Agent Prompt Templates
*To be defined for each agent role*

### B. Supported Technologies
*Comprehensive list of languages, frameworks, and tools*

### C. API Specifications
*Internal APIs for agent communication*

### D. Deployment Configurations
*Kubernetes manifests and cloud templates*

---
*Last Updated: July 4, 2025*
*Version: 1.3 - Specified Claude as primary LLM with Opus/Sonnet selection strategy*